{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import mode\n",
    "from langchain_ollama import OllamaLLM\n",
    "from pydantic_core.core_schema import model_ser_schema\n",
    "\n",
    "OllamaLLM(model=\"gemma3:270m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bfdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 多個字串(System 角色（設定模型的行為）、Human 角色（使用者的輸入）、和 AI 角色（對話歷史）)\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "# 建立多變數的翻譯模板\n",
    "complex_template = \"\"\"\n",
    "你是一位專業的{target_language}翻譯家，專精於{domain}領域。\n",
    "請將以下{source_language}文本翻譯成{target_language}，並確保：\n",
    "1. 保持原文的語氣和風格\n",
    "2. 使用專業術語\n",
    "3. 符合{target_language}的語言習慣\n",
    "\n",
    "{source_language}文本：{text}\n",
    "{target_language}翻譯：\n",
    "\"\"\"\n",
    "# ChatPromptTemplat的實體方法，傳回實體給chat_prompt_template\n",
    "# 建立 ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(complex_template)\n",
    "\n",
    "# 使用多個變數\n",
    "formatted_prompt = chat_prompt_template.format(\n",
    "    source_language=\"英文\",\n",
    "    target_language=\"繁體中文\", \n",
    "    domain=\"商業\",\n",
    "    text=\"The quarterly revenue increased by 15% compared to last year.\"\n",
    ")\n",
    "\n",
    "print(\"=== 多變數複雜模板範例 ===\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "try:\n",
    "    response = model.invoke(formatted_prompt)\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"出錯了：{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09fc3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 ===\n",
      "System: 你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "Human: The quarterly revenue increased by 15% compared to last year.\n",
      "System: 繁體中文翻譯：\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:1b模型回應:\n",
      "好的，以下是一些翻譯選項，你可以根據語氣和特定語境選擇：\n",
      "\n",
      "**選項一 (較正式):**\n",
      "\n",
      "「本季度的營收增長幅度為去年同期提升了15%。」\n",
      "\n",
      "**選項二 (較自然):**\n",
      "\n",
      "「本季度的營收比去年同期增加了15%。」\n",
      "\n",
      "**選項三 (稍帶強調):**\n",
      "\n",
      "「營收今年比去年同期增加了15%。」\n",
      "\n",
      "**選取建議：**\n",
      "\n",
      "我建議使用 **選項二**，它更自然，也更易於理解。\n",
      "\n",
      "總之，我盡力將您提供的英文句子翻譯成流暢且自然的繁體中文。\n",
      "\n",
      "您希望我針對特定情境提供翻譯嗎？ 例如，是商業報告，還是日常口語？ 這樣我可以更精準地調整翻譯。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 基本 Prompt Template 使用\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\"),\n",
    "    (\"human\", \"{english_sentence}\"),\n",
    "    (\"system\", \"繁體中文翻譯：\")\n",
    "])\n",
    "\n",
    "\n",
    "# 使用模板\n",
    "formatted_prompt = prompt_template.format(english_sentence=\"The quarterly revenue increased by 15% compared to last year.\")\n",
    "print(\"=== 基本 Prompt Template 範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Ollama gemma3:1b模型回應:\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
